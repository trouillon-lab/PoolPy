{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from Functions import *\n",
    "from Fast_functions import *\n",
    "import cmcrameri.cm as cmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dira='pooling_results/N_50/diff_2/WAs/WA_multidim-3_N_50_diff_2.csv'\n",
    "diff=2\n",
    "WA_df=pd.read_csv(dira, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WA=WA_df.values\n",
    "n_compounds=WA.shape[1]\n",
    "scrambler={1:np.arange(n_compounds)}\n",
    "for j in range(2,diff+1):\n",
    "    scrambler.update({j:np.array(list(itertools.combinations(np.arange(n_compounds),j)))})\n",
    "WA_list=[]\n",
    "multi=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrambler={1:np.arange(n_compounds)}\n",
    "for j in range(2,diff+1):\n",
    "    scrambler.update({j:np.array(list(itertools.combinations(np.arange(n_compounds),j)))})\n",
    "WA_list=[]\n",
    "multi=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]),\n",
       " 2: array([[ 0,  1],\n",
       "        [ 0,  2],\n",
       "        [ 0,  3],\n",
       "        [ 0,  4],\n",
       "        [ 0,  5],\n",
       "        [ 0,  6],\n",
       "        [ 0,  7],\n",
       "        [ 0,  8],\n",
       "        [ 0,  9],\n",
       "        [ 0, 10],\n",
       "        [ 0, 11],\n",
       "        [ 1,  2],\n",
       "        [ 1,  3],\n",
       "        [ 1,  4],\n",
       "        [ 1,  5],\n",
       "        [ 1,  6],\n",
       "        [ 1,  7],\n",
       "        [ 1,  8],\n",
       "        [ 1,  9],\n",
       "        [ 1, 10],\n",
       "        [ 1, 11],\n",
       "        [ 2,  3],\n",
       "        [ 2,  4],\n",
       "        [ 2,  5],\n",
       "        [ 2,  6],\n",
       "        [ 2,  7],\n",
       "        [ 2,  8],\n",
       "        [ 2,  9],\n",
       "        [ 2, 10],\n",
       "        [ 2, 11],\n",
       "        [ 3,  4],\n",
       "        [ 3,  5],\n",
       "        [ 3,  6],\n",
       "        [ 3,  7],\n",
       "        [ 3,  8],\n",
       "        [ 3,  9],\n",
       "        [ 3, 10],\n",
       "        [ 3, 11],\n",
       "        [ 4,  5],\n",
       "        [ 4,  6],\n",
       "        [ 4,  7],\n",
       "        [ 4,  8],\n",
       "        [ 4,  9],\n",
       "        [ 4, 10],\n",
       "        [ 4, 11],\n",
       "        [ 5,  6],\n",
       "        [ 5,  7],\n",
       "        [ 5,  8],\n",
       "        [ 5,  9],\n",
       "        [ 5, 10],\n",
       "        [ 5, 11],\n",
       "        [ 6,  7],\n",
       "        [ 6,  8],\n",
       "        [ 6,  9],\n",
       "        [ 6, 10],\n",
       "        [ 6, 11],\n",
       "        [ 7,  8],\n",
       "        [ 7,  9],\n",
       "        [ 7, 10],\n",
       "        [ 7, 11],\n",
       "        [ 8,  9],\n",
       "        [ 8, 10],\n",
       "        [ 8, 11],\n",
       "        [ 9, 10],\n",
       "        [ 9, 11],\n",
       "        [10, 11]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrambler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(WA[0]+WA[5]).astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'outcome' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdecode_precomp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwell_assigner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdifferentiate\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscrambler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscrambler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m               \u001b[49m\u001b[43mreadout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWA\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m+\u001b[49m\u001b[43mWA\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/My Drive/Git/pooling/Functions.py:915\u001b[39m, in \u001b[36mdecode_precomp\u001b[39m\u001b[34m(well_assigner, differentiate, scrambler, readout, max_differentiate, sweep, **kwargs)\u001b[39m\n\u001b[32m    912\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m outcome_dict\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         idxs = np.all(\u001b[43moutcome\u001b[49m == full_well_assigner, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    916\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(itertools.compress(sc_list,idxs))\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'outcome' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "decode_precomp(well_assigner=WA,differentiate= diff, scrambler=scrambler, \n",
    "               readout=np.array((WA[0]+WA[5]).astype(bool).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([2,5,9,54])\n",
    "b=np.array([6,1,90,5.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.maximum(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm=time.time()\n",
    "time.sleep(2.5)\n",
    "tm1=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm1-tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(itertools.combinations(np.arange(4),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=np.array([1,2,4])-1\n",
    "m3=np.arange(12).reshape(4,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(v1==m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.prod(v1==m3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1,0,0,1)==(1,1,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=list(v1)\n",
    "l1.extend(list(m3))\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuplaa=(3,6,8,2,3,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losta=[1,1,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(itertools.compress(tuplaa,losta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losta.extend([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losta.extend([3,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b='-'.join(map(str,tuplaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(b.split('-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes, counts=np.unique(m3, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=6\n",
    "dct_cmbn={}\n",
    "dct_cmbn.update({1:np.arange(N)})\n",
    "for j in range(2,5):\n",
    "    dct_cmbn.update({j:np.array(list(itertools.combinations(np.arange(N),j)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_1(combinantions_dictionary, ND=5):\n",
    "    N=combinantions_dictionary[1][-1]+1\n",
    "    new_cd={1:np.append(combinantions_dictionary[1],N)}\n",
    "    diff=1\n",
    "    while diff<(ND):\n",
    "        new_part=np.vstack([combinantions_dictionary[diff].T,np.array([N]*len(combinantions_dictionary[diff]))])\n",
    "        new_in=np.hstack([combinantions_dictionary[diff+1].T,new_part]).T\n",
    "        new_cd.update({(diff+1):new_in})\n",
    "\n",
    "        diff+=1\n",
    "    \n",
    "\n",
    "    return(new_cd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=34\n",
    "dct_cmbn={}\n",
    "dct_cmbn.update({1:np.arange(N)})\n",
    "for j in range(2,6):\n",
    "    dct_cmbn.update({j:np.array(list(itertools.combinations(np.arange(N),j)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_dict={6:dct_cmbn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_N(full_dict,N_start, N_add):\n",
    "    tmp_d=full_dict[N_start]\n",
    "    i=0\n",
    "    while i<N_add:\n",
    "        tmp_d=add_1(tmp_d)\n",
    "        full_dict.update({(N_start+i+1):tmp_d})\n",
    "        i+=1\n",
    "\n",
    "    return(full_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_add_N(dict_start, N_add, save=True,save_dir='./combinations/'):\n",
    "    tmp_d=copy.deepcopy(dict_start)\n",
    "    N_start=dict_start[1][-1]\n",
    "    i=0\n",
    "    while i<N_add:\n",
    "        print(i)\n",
    "        tmp_d=add_1(tmp_d)\n",
    "        if save:\n",
    "            NM=save_dir+'N_'+str(N_start+i+1)+'.pk'\n",
    "            with open(NM, 'wb') as handle:\n",
    "                pickle.dump(tmp_d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        i+=1\n",
    "\n",
    "    return(tmp_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WA_mat=assign_wells_mat(n_compounds=35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Random_diff_'.startswith('Ra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_cmbn[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=35\n",
    "diff=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_cmbn={}\n",
    "dct_cmbn.update({1:np.arange(N)})\n",
    "for j in range(2,diff+1):\n",
    "    dct_cmbn.update({j:np.array(list(itertools.combinations(np.arange(N),j)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=add_1(dct_cmbn, ND=diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dct_cmbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WA_mat[f1[4]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=np.bool(np.sum(WA_mat[f1[4]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#NMO=save_dir+'N_'+str(N)+'.pk'\n",
    "NMO='./combinations/N_294.pk'\n",
    "with open(NMO, \"rb\") as input_file:\n",
    "    scrambler = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrambler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT=ET-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT//3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTS=(ET - start_time)\n",
    "DTD=DTS//86400\n",
    "DTH=DTS//3600-DTD*24\n",
    "DTM=DTS//60-DTH*60-DTD*24*60\n",
    "DTS1=DTS-(DTM+DTH*60+DTD*24*60)*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_consistent_precomp(well_assigner:np.array, differentiate:int, scrambler:dict) -> list:\n",
    "    if differentiate==0:\n",
    "        return(True,well_assigner, np.array([1]*well_assigner.shape[0]))\n",
    "    N=well_assigner.shape[0]\n",
    "    for i in range(differentiate):\n",
    "        diff=i+1\n",
    "        if diff ==1:\n",
    "            full_well_assigner=well_assigner.copy()\n",
    "        else:\n",
    "            this_sc=scrambler[diff]\n",
    "            full_well_assigner=np.concatenate((full_well_assigner,np.bool(np.sum(well_assigner[this_sc], axis=1))))\n",
    "    _, counts=np.unique(full_well_assigner, axis=0, return_counts=True)\n",
    "    if len(counts)<full_well_assigner.shape[0]:\n",
    "        return(False, full_well_assigner, counts)\n",
    "    elif len(counts)==full_well_assigner.shape[0]:\n",
    "        return(True,full_well_assigner, counts)\n",
    "    else:\n",
    "        print(\"Something is fishy\")\n",
    "        return(-1)\n",
    "    \n",
    "#\n",
    "def mean_metrics_precomp(well_assigner, differentiate, scrambler, **kwargs):\n",
    "    BT=well_assigner.shape[1]\n",
    "    _,_, counts= is_consistent_precomp(well_assigner, differentiate, scrambler) \n",
    "    ET=extra_tests(counts)   \n",
    "    rounds=np.sum(counts>1)/np.sum(counts>0)+1\n",
    "    p_check=np.round(np.sum(counts[counts>1])/np.sum(counts)*100)\n",
    "    return BT+ET, ET,  rounds, p_check\n",
    "\n",
    "def decode_precomp(well_assigner:np.ndarray, readout:np.ndarray, differentiate:int, scrambler:dict) -> list:\n",
    "    N=well_assigner.shape[0]\n",
    "    for i in range(differentiate):\n",
    "        resulti=[]\n",
    "        diff=i+1\n",
    "        if diff ==1:\n",
    "            resulti.extend(list(range(well_assigner.shape[0])))\n",
    "            full_well_assigner=well_assigner.copy()\n",
    "        else:\n",
    "            this_sc=scrambler[diff]\n",
    "            full_well_assigner=np.concatenate((full_well_assigner,np.bool(np.sum(well_assigner[this_sc], axis=1))))\n",
    "    idxs=[i for i in range(full_well_assigner.shape[0]) if np.array_equal(full_well_assigner[i,:],readout)]\n",
    "    if len(idxs)==0:\n",
    "        print('No match')\n",
    "        return(-1)\n",
    "    \n",
    "    return [resulti[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_C(n_compounds, max_compounds):\n",
    "    MC= int(n_compounds/2) if max_compounds==0 else max_compounds\n",
    "def get_min_C(n_compounds, MC):\n",
    "    mc=int(np.sqrt(n_compounds)) if int(np.sqrt(n_compounds))<MC else int(MC/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_C(n_compounds, max_compounds):\n",
    "    return int(n_compounds/2) if max_compounds==0 else max_compounds\n",
    "def get_min_C(n_compounds, MC):\n",
    "    return int(np.sqrt(n_compounds)) if int(np.sqrt(n_compounds))<MC else int(MC/2)\n",
    "\n",
    "def get_max_W(n_compounds):\n",
    "    return int(np.log2(n_compounds))\n",
    "def get_min_W(n_compounds):\n",
    "    return int(2*np.sqrt(n_compounds))\n",
    "\n",
    "def find_rand_params_precomp(n_compounds:int, n_compounds_per_well=0, n_wells=0, guesses=0, \n",
    "                     max_compounds=0, max_redundancy=4, min_redundancy=1,**kwargs):\n",
    "    skip_compounds=True\n",
    "    skip_wells=True\n",
    "    if n_compounds_per_well==0:\n",
    "        skip_compounds=False\n",
    "    if n_wells==0:\n",
    "        skip_wells=False\n",
    "    if guesses==0:\n",
    "        guesses=n_compounds\n",
    "\n",
    "    MC= get_max_C(n_compounds, max_compounds)\n",
    "    mc=get_min_C(n_compounds, MC)\n",
    "    arr_comp=np.arange(int(mc),int(MC+1))\n",
    "    mw=get_min_W(n_compounds)\n",
    "    MW=get_max_W(n_compounds)\n",
    "    while MW-mw<10:\n",
    "        mw=int(abs(mw-1))\n",
    "        MW=int(MW+1)\n",
    "\n",
    "    arr_wells=np.arange(mw,MW)\n",
    "    min_tests=np.inf\n",
    "    for comp in arr_comp:\n",
    "        if skip_compounds:\n",
    "            comp=n_compounds_per_well\n",
    "\n",
    "        for wells in arr_wells:\n",
    "            if skip_wells:\n",
    "                if skip_compounds:\n",
    "                    \n",
    "                    return n_compounds_per_well, n_wells, assign_wells_random_precomp( Evaluate=True, **kwargs)\n",
    "                wells=n_wells\n",
    "                \n",
    "            if comp*wells>max_redundancy*n_compounds*np.log2(n_compounds) or comp*wells<min_redundancy*n_compounds: continue \n",
    "            WA_tmp, mean_exp, p_check=assign_wells_random_precomp(Evaluate=True, return_me=True, **kwargs)\n",
    "            if mean_exp<min_tests:\n",
    "                Comp=comp\n",
    "                Wells=wells\n",
    "                min_tests=mean_exp\n",
    "                min_wa=WA_tmp\n",
    "                min_pcheck=p_check\n",
    "            if skip_wells:\n",
    "                break\n",
    "        if skip_compounds:\n",
    "            break\n",
    "\n",
    "    return Comp, Wells, min_tests, min_wa, min_pcheck\n",
    "\n",
    "def assign_wells_random_precomp(n_compounds:int,  differentiate:int,scrambler:dict, n_compounds_per_well=0, \n",
    "                        n_wells=0, guesses=0, Evaluate=False, return_me=False, **kwargs)->np.array:\n",
    "    if guesses==0:\n",
    "        guesses=n_compounds\n",
    "    min_tests=np.inf\n",
    "\n",
    "    if n_compounds_per_well==0 or n_wells==0:\n",
    "        _,_, min_tests, WA_rand, p_check=find_rand_params_precomp(**kwargs)\n",
    "        if return_me:\n",
    "            return WA_rand,  min_tests, p_check\n",
    "        \n",
    "        return WA_rand\n",
    "        \n",
    "\n",
    "\n",
    "    if Evaluate:\n",
    "        second_axis=np.tile(np.arange(n_wells),n_compounds_per_well).reshape(n_compounds_per_well,-1)\n",
    "        for i in range(guesses):\n",
    "            idt=np.random.randint(0,n_compounds,size=(n_compounds_per_well,n_wells) )\n",
    "            well_assigner=np.zeros((n_compounds,n_wells))==1\n",
    "            well_assigner[idt, second_axis]=True\n",
    "            if guesses==1:\n",
    "                if return_me:\n",
    "                    mean_exp, _, _, p_check= mean_metrics_precomp(well_assigner=well_assigner, \n",
    "                                                                differentiate=differentiate,scrambler=scrambler,**kwargs)\n",
    "                    return well_assigner, mean_exp, p_check\n",
    "                return well_assigner\n",
    "            mean_exp, _, _, p_check= mean_metrics_precomp(well_assigner=well_assigner,\n",
    "                                                        differentiate=differentiate, scrambler=scrambler, **kwargs)\n",
    "            if p_check<1:\n",
    "                if return_me:\n",
    "                    return well_assigner,  mean_exp, p_check\n",
    "                return well_assigner\n",
    "            elif mean_exp<min_tests: \n",
    "                best_wa=well_assigner.copy()\n",
    "                min_tests=mean_exp\n",
    "                min_pcheck=p_check\n",
    "\n",
    "        if return_me:\n",
    "            return best_wa,  min_tests, min_pcheck\n",
    "        \n",
    "        return best_wa\n",
    "\n",
    "    _,_, min_tests, WA_rand, p_check=find_rand_params_precomp(n_compounds=n_compounds, differentiate=differentiate, \n",
    "                                 n_compounds_per_well=n_compounds_per_well, n_wells=n_wells, \n",
    "                                 guesses=guesses,scrambler=scrambler, **kwargs)\n",
    "    if return_me:\n",
    "        return WA_rand,  min_tests, p_check\n",
    "    \n",
    "    return WA_rand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_sweep_diff(n_compounds, max_diff, dir_scramblers, Npath, **kwargs):\n",
    "    if 'differentiate' in kwargs.keys():\n",
    "        del kwargs['differentiate']\n",
    "    if max_diff>1:\n",
    "\n",
    "        for di in range(max_diff):\n",
    "            diff=di+1\n",
    "            if diff==1:\n",
    "                dpath=os.path.join(Npath,'diff_'+str(diff))\n",
    "                WApath=os.path.join(dpath,'WAs')\n",
    "                scrambler={1:np.arange(n_compounds)}\n",
    "                WA_rand,  min_tests, perc_check=assign_wells_random_precomp(n_compounds=n_compounds, \n",
    "                                                                differentiate=diff,scrambler=scrambler, return_me=True )\n",
    "                extra_exp=WA_rand.shape[1]+min_tests\n",
    "                #.append(['Random', min_tests, np.max(np.sum(WA_rand, axis=0)), WA_rand.shape[0], int(perc_check),  extra_exp,1+perc_check/100])\n",
    "                full_file_dir=os.path.join(dpath,'Random_diff_'+str(diff)+'_NS_'+\n",
    "                                               str(n_compounds)+'_NW_'+str(WA_rand.shape[0])+\n",
    "                                               '_MS_'+str(np.max(np.sum(WA_rand, axis=0)))+\n",
    "                                                '_PC_'+ str(int(perc_check)) +'_EE_'+str(extra_exp)+\".txt\")\n",
    "                if not os.path.exists(dpath):\n",
    "                    os.makedirs(dpath)\n",
    "                open(full_file_dir, 'a').close()\n",
    "                if not os.path.exists(WApath):\n",
    "                    os.makedirs(WApath)\n",
    "                thisfile=os.path.join(WApath,'WA_Random_N_'+str(n_compounds)+'_diff_'+str(diff)+'.csv')\n",
    "                np.savetxt(thisfile, WA_rand.astype(bool), delimiter=\",\")\n",
    "\n",
    "\n",
    "            else:\n",
    "                this_sc_file=os.path.join(dir_scramblers, 'N_'+str(N),  'N_'+str(N)+'_diff_'+str(diff)+'.npz')\n",
    "                this_scrambler=np.load(this_sc_file)['sc']\n",
    "                scrambler.update({diff:this_scrambler})\n",
    "                WA_rand,  min_tests, perc_check=assign_wells_random_precomp(n_compounds=n_compounds, \n",
    "                                                                differentiate=diff,scrambler=scrambler, return_me=True )\n",
    "                extra_exp=WA_rand.shape[1]+min_tests\n",
    "                #.append(['Random', min_tests, np.max(np.sum(WA_rand, axis=0)), WA_rand.shape[0], int(perc_check),  extra_exp,1+perc_check/100])\n",
    "                full_file_dir=os.path.join(dpath,'RAND_diff_'+str(diff)+'_NS_'+\n",
    "                                               str(n_compounds)+'_NW_'+str(WA_rand.shape[0])+\n",
    "                                               '_MS_'+str(np.max(np.sum(WA_rand, axis=0)))+\n",
    "                                                '_PC_'+ str(int(perc_check)) +'_EE_'+str(extra_exp)+\".txt\")\n",
    "                if not os.path.exists(dpath):\n",
    "                    os.makedirs(dpath)\n",
    "                open(full_file_dir, 'a').close()\n",
    "                if not os.path.exists(WApath):\n",
    "                    os.makedirs(WApath)\n",
    "                thisfile=os.path.join(WApath,'WA_Random_N_'+str(n_compounds)+'_diff_'+str(diff)+'.csv')\n",
    "                np.savetxt(thisfile, WA_rand.astype(bool), delimiter=\",\")\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_N_sweep(N_min, N_max, **kwargs):\n",
    "    for n_compounds in np.arange(N_min, N_max+1):\n",
    "        rand_sweep_diff(n_compounds=n_compounds, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_deterministic_WAs(start=50, stop=150, step=10, **kwargs):\n",
    "    dict_comp={}\n",
    "    current=start\n",
    "    while current<stop:\n",
    "        time0=time.time()\n",
    "        if kwargs['timeit']:\n",
    "            print(current)\n",
    "        full_deterministic_WAS(n_compounds=current, **kwargs)\n",
    "        current=current+step\n",
    "        if kwargs['timeit']:\n",
    "            print(\"segment time: %s seconds\" % np.round(time.time() - time0, 1))\n",
    "\n",
    "\n",
    "def full_deterministic_WAS(**kwargs):\n",
    "    #methods=['matrix', 'random', 'STD', 'Chinese trick']\n",
    "    # matrix assignment\n",
    "    \n",
    "    kwargs['return_wa']=True\n",
    "\n",
    "    WA_list=[]\n",
    "    multi=[]\n",
    "    for i in np.arange(2,int(np.ceil(np.log(kwargs['n_compounds'])/np.log(2)))):\n",
    "        if i>kwargs['max_dims']:\n",
    "            continue\n",
    "        WA_mul=assign_wells_multidim(n_dims=i, **kwargs)\n",
    "        WA_list.append(WA_mul)\n",
    "        multi.append('multidim-'+str(i))\n",
    "        \n",
    "    methods=multi.copy()\n",
    "\n",
    "    WA_mat=assign_wells_mat(**kwargs)\n",
    "\n",
    "    WA_list.append(WA_mat)\n",
    "    methods.append('Matrix')\n",
    "\n",
    "    WA_bin=assign_wells_L(**kwargs)\n",
    "    methods.append('Binary')\n",
    "    WA_list.append(WA_bin)\n",
    "\n",
    "    if kwargs['max_diff']>1:\n",
    "        for diffo in np.arange(kwargs['max_diff']):\n",
    "            diff=diffo+1\n",
    "\n",
    "            WA_listo=copy.deepcopy(WA_list)\n",
    "            methodso=copy.deepcopy(methods)\n",
    "\n",
    "            # STD asignment \n",
    "            WA_std=assign_wells_STD(differentiate=diff,**kwargs)\n",
    "\n",
    "            \n",
    "\n",
    "            # chinese trick assignment\n",
    "            WA_chin=assign_wells_chinese(differentiate=diff,**kwargs)\n",
    "\n",
    "\n",
    "            WA_listo.extend([ WA_std, WA_chin])\n",
    "            methodso.extend(['STD', 'Chinese trick'])\n",
    "\n",
    "\n",
    "\n",
    "            this_dir=os.path.join(kwargs['save_dir'],'N_'+str(kwargs['n_compounds']), 'diff_'+str(diff), 'WAs')\n",
    "\n",
    "            if not os.path.exists(this_dir):\n",
    "                os.makedirs(this_dir)\n",
    "\n",
    "            for method, WA in zip(methods, WA_list):\n",
    "                thisfile=os.path.join(this_dir,'WA_'+ method+'_N_'+str(kwargs['n_compounds'])+'_diff_'+str(diff)+'.csv')\n",
    "                np.savetxt(thisfile, WA.astype(bool), delimiter=\",\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "\n",
    "\n",
    "        WA_listo=copy.deepcopy(WA_list)\n",
    "        methodso=copy.deepcopy(methods)\n",
    "\n",
    "        # STD asignment \n",
    "        WA_std=assign_wells_STD(**kwargs)\n",
    "\n",
    "        \n",
    "\n",
    "        # chinese trick assignment\n",
    "        WA_chin=assign_wells_chinese(**kwargs)\n",
    "\n",
    "\n",
    "        WA_listo.extend([ WA_std, WA_chin])\n",
    "        methodso.extend(['STD', 'Chinese trick'])\n",
    "\n",
    "\n",
    "\n",
    "        this_dir=os.path.join(kwargs['save_dir'],'N_'+str(kwargs['n_compounds']), 'diff_'+str(kwargs['differentiate']), 'WAs')\n",
    "\n",
    "        if not os.path.exists(this_dir):\n",
    "            os.makedirs(this_dir)\n",
    "\n",
    "        for method, WA in zip(methods, WA_list):\n",
    "            thisfile=os.path.join(this_dir,'WA_'+ method+'_N_'+str(kwargs['n_compounds'])+'_diff_'+str(kwargs['differentiate']+'.csv'))\n",
    "            np.savetxt(thisfile, WA.astype(bool), delimiter=\",\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #hierarchical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_all_deterministic_WAs(max_diff=4, timeit=True, max_dims=20, save_dir='./outs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_consistent_precomp(well_assigner:np.array, differentiate:int, scrambler:dict) -> list:\n",
    "    if differentiate==0:\n",
    "        return(True,well_assigner, np.array([1]*well_assigner.shape[0]))\n",
    "    N=well_assigner.shape[0]\n",
    "    for i in range(differentiate):\n",
    "        diff=i+1\n",
    "        if diff ==1:\n",
    "            full_well_assigner=well_assigner.copy()\n",
    "        else:\n",
    "            this_sc=scrambler[diff]\n",
    "            full_well_assigner=np.concatenate((full_well_assigner,np.bool(np.sum(well_assigner[this_sc], axis=1))))\n",
    "    _, counts=np.unique(full_well_assigner, axis=0, return_counts=True)\n",
    "    if len(counts)<full_well_assigner.shape[0]:\n",
    "        return(False, full_well_assigner, counts)\n",
    "    elif len(counts)==full_well_assigner.shape[0]:\n",
    "        return(True,full_well_assigner, counts)\n",
    "    else:\n",
    "        print(\"Something is fishy\")\n",
    "        return(-1)\n",
    "    \n",
    "def is_consistent_precomp_alldiff(well_assigner:np.array, max_diff:int, scrambler:dict) -> list:\n",
    "    if max_diff==0:\n",
    "        return(True,well_assigner, np.array([1]*well_assigner.shape[0]))\n",
    "    N=well_assigner.shape[0]\n",
    "    dict_counts={}\n",
    "    for i in range(max_diff):\n",
    "        diff=i+1\n",
    "        if diff ==1:\n",
    "            full_well_assigner=well_assigner.copy()\n",
    "        else:\n",
    "            this_sc=scrambler[diff]\n",
    "            full_well_assigner=np.concatenate((full_well_assigner,np.bool(np.sum(well_assigner[this_sc], axis=1))))\n",
    "\n",
    "        _, counts=np.unique(full_well_assigner, axis=0, return_counts=True)\n",
    "        dict_counts.update({diff:counts})\n",
    "    return dict_counts\n",
    "\n",
    "def mean_metrics_precomp(well_assigner, differentiate, scrambler, **kwargs):\n",
    "    BT=well_assigner.shape[1]\n",
    "    _,_, counts= is_consistent_precomp(well_assigner, differentiate, scrambler) \n",
    "    ET=extra_tests(counts)   \n",
    "    rounds=np.sum(counts>1)/np.sum(counts>0)+1\n",
    "    p_check=np.round(np.sum(counts[counts>1])/np.sum(counts)*100)\n",
    "    return BT+ET, ET,  rounds, p_check\n",
    "    \n",
    "#\n",
    "def mean_metrics_precomp_alldiff(well_assigner, max_diff, scrambler, **kwargs):\n",
    "    BT=well_assigner.shape[1]\n",
    "    dict_counts= is_consistent_precomp_alldiff(well_assigner, max_diff, scrambler) \n",
    "    dict_res={}\n",
    "    for difo, counts in dict_counts.items():\n",
    "        ET=extra_tests(counts)   \n",
    "        rounds=np.sum(counts>1)/np.sum(counts>0)+1\n",
    "        p_check=np.round(np.sum(counts[counts>1])/np.sum(counts)*100)\n",
    "        dict_res.update({difo:[BT+ET, ET,  rounds, p_check]})\n",
    "    return dict_res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_metrics_precomp(dir_scramblers, dir_WAs, max_diff, start=50, stop=150, step=10, diff=2, **kwargs):\n",
    "    N=start\n",
    "    ls_names_met=['Method', 'Mean experiments', 'Max compunds per well', 'N wells', 'Percentage check', 'Mean extra experiments', 'Mean steps']\n",
    "    while N<stop:\n",
    "        Npath=os.path.join(dir_WAs,'N_'+str(N))\n",
    "        diff=1\n",
    "        if max_diff>1:\n",
    "            \n",
    "            while diff<=max_diff:\n",
    "                dpath=os.path.join(Npath,'diff_'+str(diff))\n",
    "                ls_met=[]\n",
    "                full_methods=[]\n",
    "                if diff==1:\n",
    "                    scrambler={1:np.arange(N)}\n",
    "                    WApath=os.path.join(dpath,'WAs')\n",
    "                    filenames = next(os.walk(WApath), (None, None, []))[2]\n",
    "                    for fname in filenames:\n",
    "                        WA=np.genfromtxt(fname, delimiter=\",\")\n",
    "                        mean_exp, extra_exp,  _, perc_check= mean_metrics_precomp(WA=WA,scrambler=scrambler, \n",
    "                                                                                  differentiate=diff, **kwargs)\n",
    "                        n_wells=WA.shape[1]\n",
    "                        M_exp=np.round(mean_exp, 2)\n",
    "                        max_comp=np.max(np.sum(WA, axis=0))\n",
    "                        method=re.sub('^WA_', '', fname)\n",
    "                        method=re.sub('_.*$', '', method)\n",
    "                        ls_met.append([method, M_exp, max_comp, n_wells, int(perc_check),  extra_exp,1+perc_check/100])\n",
    "                        full_methods.append(method)\n",
    "                        \n",
    "                    Hier=calculate_metrics_hierarchical(n_compounds=N, differentiate=diff, **kwargs)\n",
    "                    ls_met.append(['Hierarchical']+ [Hier[:-1]])\n",
    "                    full_methods.append('Hierarchical')\n",
    "                    df_met=pd.DataFrame(ls_met)\n",
    "                    #dft=pd.DataFrame({'Method':[a[0] for a in ls_met], 'Mean Experiments':[a[1] for a in ls_met],\n",
    "                    #                    'Max compunds':[a[2] for a in ls_met], 'N wells':[a[3] for a in ls_met],\n",
    "                    #                    'Percentage check':[a[4] for a in ls_met], 'Extra experiments':[a[5] for a in ls_met],\n",
    "                    #                    'Mean steps':[a[6] for a in ls_met],})\n",
    "\n",
    "\n",
    "\n",
    "                    idx_renamer={i:j for i,j in zip(df_met.index, full_methods)}\n",
    "                    col_renamer={i:j for i,j in zip(df_met.columns, ls_names_met)}\n",
    "                    df_met.rename(index=idx_renamer, columns=col_renamer, inplace=True)\n",
    "                    metname=os.path.join(dpath, 'Metrics_N_'+str(N)+'_diff_'+str(diff)+'.csv')\n",
    "                    df_met.to_csv(metname)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    this_sc_file=os.path.join(dir_scramblers, 'N_'+str(N),  'N_'+str(N)+'_diff_'+str(diff)+'.npz')\n",
    "                    scrambler.update({diff:this_sc_file})\n",
    "                    dpath=os.path.join(Npath,'diff_'+str(diff),'WAs')\n",
    "                    filenames = next(os.walk(dpath), (None, None, []))[2]\n",
    "                    for fname in filenames:\n",
    "                        WA=np.genfromtxt(fname, delimiter=\",\")\n",
    "                        mean_exp, extra_exp,  _, perc_check= mean_metrics_precomp(WA=WA,scrambler=scrambler, \n",
    "                                                                                  differentiate=diff, **kwargs)\n",
    "                        n_wells=WA.shape[1]\n",
    "                        M_exp=np.round(mean_exp, 2)\n",
    "                        max_comp=np.max(np.sum(WA, axis=0))\n",
    "                        method=re.sub('^WA_', '', fname)\n",
    "                        method=re.sub('_.*$', '', method)\n",
    "                        ls_met.append([method, M_exp, max_comp, n_wells, int(perc_check),  extra_exp,1+perc_check/100])\n",
    "                        full_methods.append(method)\n",
    "                    Hier=calculate_metrics_hierarchical(n_compounds=N, differentiate=diff, **kwargs)\n",
    "                    ls_met.append(['Hierarchical']+ [Hier[:-1]])\n",
    "                    full_methods.append('Hierarchical')\n",
    "                    df_met=pd.DataFrame(ls_met)\n",
    "                    #dft=pd.DataFrame({'Method':[a[0] for a in ls_met], 'Mean Experiments':[a[1] for a in ls_met],\n",
    "                    #                    'Max compunds':[a[2] for a in ls_met], 'N wells':[a[3] for a in ls_met],\n",
    "                    #                    'Percentage check':[a[4] for a in ls_met], 'Extra experiments':[a[5] for a in ls_met],\n",
    "                    #                    'Mean steps':[a[6] for a in ls_met],})\n",
    "\n",
    "\n",
    "\n",
    "                    idx_renamer={i:j for i,j in zip(df_met.index, full_methods)}\n",
    "                    col_renamer={i:j for i,j in zip(df_met.columns, ls_names_met)}\n",
    "                    df_met.rename(index=idx_renamer, columns=col_renamer, inplace=True)\n",
    "                    metname=os.path.join(dpath, 'Metrics_N_'+str(N)+'_diff_'+str(diff)+'.csv')\n",
    "                    df_met.to_csv(metname)\n",
    "                    \n",
    "\n",
    "        elif max_diff==1:\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_met=[[1,2],[1,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_met=pd.DataFrame(ls_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.load('/Users/ltalamanca/My Drive/Git/pooling/combinations/N_50/N_50_diff_2.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['sc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undiff_WAS(**kwargs):\n",
    "    methods=['matrix', 'random', 'STD', 'Chinese trick']\n",
    "    # matrix assignment\n",
    "    \n",
    "\n",
    "    # multidimensional matrix\n",
    "    if 'n_dims' in kwargs.keys():\n",
    "        WA_mul=assign_wells_multidim(**kwargs)\n",
    "        ndmin=kwargs['n_dims']\n",
    "        multi=['multidim: '+str(ndmin)]\n",
    "        WA_list=[WA_mul]\n",
    "    elif 'all_dims' in kwargs.keys():\n",
    "        if kwargs['all_dims']:\n",
    "            WA_list=[]\n",
    "            multi=[]\n",
    "            for i in np.arange(2,int(np.ceil(np.log(kwargs['n_compounds'])/np.log(2)))):\n",
    "                if i>kwargs['max_dims']:\n",
    "                    continue\n",
    "                WA_mul=assign_wells_multidim(n_dims=i, **kwargs)\n",
    "                WA_list.append(WA_mul)\n",
    "                multi.append('Multidim_'+str(i))\n",
    "\n",
    "        else:\n",
    "            ndmin= find_dims(**kwargs)\n",
    "            WA_mul=assign_wells_multidim(n_dims=ndmin, **kwargs)\n",
    "            multi=['Multidim_'+str(ndmin)]\n",
    "            WA_list=[WA_mul]\n",
    "            \n",
    "\n",
    "\n",
    "    else:\n",
    "        ndmin= find_dims(**kwargs)\n",
    "        WA_mul=assign_wells_multidim(n_dims=ndmin, **kwargs)\n",
    "        multi=['multidim: '+str(ndmin)]\n",
    "        WA_list=[WA_mul]\n",
    "    \n",
    "    multi.append('Matrix')\n",
    "    methods=multi.copy()\n",
    "\n",
    "    WA_mat=assign_wells_mat(**kwargs)\n",
    "\n",
    "\n",
    "    WA_list.append(WA_mat)\n",
    "\n",
    "    if kwargs['differentiate']<2:\n",
    "        WA_bin=assign_wells_L(**kwargs)\n",
    "        methods.append('Binary')\n",
    "        WA_list.append(WA_bin)\n",
    "\n",
    "    #hierarchical\n",
    "        \n",
    "    Hier=calculate_metrics_hierarchical(**kwargs)\n",
    "    #return([BM[0], BM[1],layers, MC, details ])\n",
    "\n",
    "    ls_met=[]\n",
    "    ls_names_met=['mean_experiments', 'max_compounds_per_well', 'n_wells', 'percentage_check', 'mean_extra_exp', 'mean_steps']\n",
    "    for method, WA in zip(methods, WA_list):\n",
    "        mean_exp, extra_exp,  _, perc_check= mean_metrics(WA, **kwargs)\n",
    "        n_wells=WA.shape[1]\n",
    "        M_exp=np.round(mean_exp, 2)\n",
    "        max_comp=np.max(np.sum(WA, axis=0))\n",
    "        ls_met.append([M_exp, max_comp, n_wells, int(perc_check),  extra_exp,1+perc_check/100])\n",
    "    ls_met.append(Hier[:-1])\n",
    "    full_methods=methods.copy()\n",
    "    full_methods.append('Hierarchical')\n",
    "    df_met=pd.DataFrame(ls_met)\n",
    "\n",
    "    dict_wa={method: WA for method, WA in zip(methods, WA_list)}\n",
    "    dict_wa.update({'Hierarchical':Hier[5]})\n",
    "\n",
    "    idx_renamer={i:j for i,j in zip(df_met.index, full_methods)}\n",
    "    col_renamer={i:j for i,j in zip(df_met.columns, ls_names_met)}\n",
    "    df_met.rename(index=idx_renamer, columns=col_renamer, inplace=True)\n",
    "\n",
    "    ret_wa= kwargs['return_wa'] \n",
    "    if ret_wa:\n",
    "        return df_met, dict_wa\n",
    "    return df_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_deterministic_WAS(**kwargs):\n",
    "    methods=['matrix', 'random', 'STD', 'Chinese trick']\n",
    "    # matrix assignment\n",
    "    \n",
    "\n",
    "    # multidimensional matrix\n",
    "    if 'n_dims' in kwargs.keys():\n",
    "        WA_mul=assign_wells_multidim(**kwargs)\n",
    "        ndmin=kwargs['n_dims']\n",
    "        multi=['multidim: '+str(ndmin)]\n",
    "        WA_list=[WA_mul]\n",
    "    elif 'all_dims' in kwargs.keys():\n",
    "        if kwargs['all_dims']:\n",
    "            WA_list=[]\n",
    "            multi=[]\n",
    "            for i in np.arange(2,int(np.ceil(np.log(kwargs['n_compounds'])/np.log(2)))):\n",
    "                if i>kwargs['max_dims']:\n",
    "                    continue\n",
    "                WA_mul=assign_wells_multidim(n_dims=i, **kwargs)\n",
    "                WA_list.append(WA_mul)\n",
    "                multi.append('multidim: '+str(i))\n",
    "\n",
    "        else:\n",
    "            ndmin= find_dims(**kwargs)\n",
    "            WA_mul=assign_wells_multidim(n_dims=ndmin, **kwargs)\n",
    "            multi=['multidim: '+str(ndmin)]\n",
    "            WA_list=[WA_mul]\n",
    "            \n",
    "\n",
    "\n",
    "    else:\n",
    "        ndmin= find_dims(**kwargs)\n",
    "        WA_mul=assign_wells_multidim(n_dims=ndmin, **kwargs)\n",
    "        multi=['multidim: '+str(ndmin)]\n",
    "        WA_list=[WA_mul]\n",
    "    \n",
    "    multi.extend(methods)\n",
    "    methods=multi.copy()\n",
    "\n",
    "    WA_mat=assign_wells_mat(**kwargs)\n",
    "\n",
    "    # random assignment\n",
    "\n",
    "    WA_ran=assign_wells_random(**kwargs)\n",
    "\n",
    "    # STD asignment \n",
    "    WA_std=assign_wells_STD(**kwargs)\n",
    "\n",
    "    \n",
    "\n",
    "    # chinese trick assignment\n",
    "    WA_chin=assign_wells_chinese(**kwargs)\n",
    "\n",
    "\n",
    "    WA_list.extend([WA_mat, WA_ran,WA_std, WA_chin])\n",
    "\n",
    "    if kwargs['differentiate']<2:\n",
    "        WA_bin=assign_wells_L(**kwargs)\n",
    "        methods.append('Binary')\n",
    "        WA_list.append(WA_bin)\n",
    "\n",
    "    #hierarchical\n",
    "        \n",
    "    Hier=calculate_metrics_hierarchical(**kwargs)\n",
    "    #return([BM[0], BM[1],layers, MC, details ])\n",
    "\n",
    "    ls_met=[]\n",
    "    ls_names_met=['mean_experiments', 'max_compounds_per_well', 'n_wells', 'percentage_check', 'mean_extra_exp', 'mean_steps']\n",
    "    for method, WA in zip(methods, WA_list):\n",
    "        mean_exp, extra_exp,  _, perc_check= mean_metrics(WA, **kwargs)\n",
    "        n_wells=WA.shape[1]\n",
    "        M_exp=np.round(mean_exp, 2)\n",
    "        max_comp=np.max(np.sum(WA, axis=0))\n",
    "        ls_met.append([M_exp, max_comp, n_wells, int(perc_check),  extra_exp,1+perc_check/100])\n",
    "    ls_met.append(Hier[:-1])\n",
    "    full_methods=methods.copy()\n",
    "    full_methods.append('Hierarchical')\n",
    "    df_met=pd.DataFrame(ls_met)\n",
    "\n",
    "    dict_wa={method: WA for method, WA in zip(methods, WA_list)}\n",
    "    dict_wa.update({'Hierarchical':Hier[5]})\n",
    "\n",
    "    idx_renamer={i:j for i,j in zip(df_met.index, full_methods)}\n",
    "    col_renamer={i:j for i,j in zip(df_met.columns, ls_names_met)}\n",
    "    df_met.rename(index=idx_renamer, columns=col_renamer, inplace=True)\n",
    "\n",
    "    ret_wa= kwargs['return_wa'] \n",
    "    if ret_wa:\n",
    "        return df_met, dict_wa\n",
    "    return df_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_wells_random_precomp(n_compounds:int,  differentiate:int,scrambler:dict, n_compounds_per_well=0, \n",
    "                        n_wells=0, guesses=0, Evaluate=False, return_me=False, **kwargs)->np.array:\n",
    "    if guesses==0:\n",
    "        guesses=n_compounds\n",
    "    min_tests=np.inf\n",
    "\n",
    "    if n_compounds_per_well==0 or n_wells==0:\n",
    "        _,_, min_tests, WA_rand=find_rand_params_precomp(n_compounds=n_compounds, differentiate=differentiate, \n",
    "                                 n_compounds_per_well=n_compounds_per_well, n_wells=n_wells, guesses=guesses,\n",
    "                                 scrambler=scrambler)\n",
    "        if return_me:\n",
    "            return WA_rand,  min_tests\n",
    "        \n",
    "        return WA_rand\n",
    "        \n",
    "\n",
    "\n",
    "    if Evaluate:\n",
    "        second_axis=np.tile(np.arange(n_wells),n_compounds_per_well).reshape(n_compounds_per_well,-1)\n",
    "        for i in range(guesses):\n",
    "            idt=np.random.randint(0,n_compounds,size=(n_compounds_per_well,n_wells) )\n",
    "            well_assigner=np.zeros((n_compounds,n_wells))==1\n",
    "            well_assigner[idt, second_axis]=True\n",
    "            if guesses==1:\n",
    "                if return_me:\n",
    "                    mean_exp, _, _, p_check= mean_metrics_precomp(well_assigner=well_assigner, \n",
    "                                                                differentiate=differentiate,scrambler=scrambler)\n",
    "                    return well_assigner, mean_exp\n",
    "                return well_assigner\n",
    "            mean_exp, _, _, p_check= mean_metrics_precomp(well_assigner=well_assigner,\n",
    "                                                        differentiate=differentiate, scrambler=scrambler)\n",
    "            if p_check<1:\n",
    "                if return_me:\n",
    "                    return well_assigner,  mean_exp\n",
    "                return well_assigner\n",
    "            elif mean_exp<min_tests: \n",
    "                best_wa=well_assigner.copy()\n",
    "                min_tests=mean_exp\n",
    "\n",
    "        if return_me:\n",
    "            return best_wa,  min_tests\n",
    "        \n",
    "        return best_wa\n",
    "\n",
    "    _,_, min_tests, WA_rand=find_rand_params_precomp(n_compounds=n_compounds, differentiate=differentiate, \n",
    "                                 n_compounds_per_well=n_compounds_per_well, n_wells=n_wells, \n",
    "                                 guesses=guesses,scrambler=scrambler)\n",
    "    if return_me:\n",
    "        return WA_rand,  min_tests\n",
    "    \n",
    "    return WA_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WA=assign_wells_mat(n_compounds=296)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrambler[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bool(np.sum(WA[scrambler[3]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_consistent_precomp(WA,3,scrambler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_metrics_precomp(well_assigner, differentiate, scrambler, **kwargs):\n",
    "    BT=well_assigner.shape[1]\n",
    "    _,_, counts= is_consistent_precomp(well_assigner, differentiate, scrambler) \n",
    "    ET=extra_tests(counts)   \n",
    "    rounds=np.sum(counts>1)/np.sum(counts>0)+1\n",
    "    p_check=np.round(np.sum(counts[counts>1])/np.sum(counts)*100)\n",
    "    return BT+ET, ET,  rounds, p_check\n",
    "\n",
    "def decode_precomp(well_assigner:np.ndarray, readout:np.ndarray, differentiate:int, scrambler:dict) -> list:\n",
    "    N=well_assigner.shape[0]\n",
    "    for i in range(differentiate):\n",
    "        resulti=[]\n",
    "        diff=i+1\n",
    "        if diff ==1:\n",
    "            resulti.extend(list(range(well_assigner.shape[0])))\n",
    "            full_well_assigner=well_assigner.copy()\n",
    "        else:\n",
    "            this_sc=scrambler[diff]\n",
    "            full_well_assigner=np.concatenate((full_well_assigner,np.bool(np.sum(well_assigner[this_sc], axis=1))))\n",
    "    idxs=[i for i in range(full_well_assigner.shape[0]) if np.array_equal(full_well_assigner[i,:],readout)]\n",
    "    if len(idxs)==0:\n",
    "        print('No match')\n",
    "        return(-1)\n",
    "    \n",
    "    return [resulti[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_precomp(well_assigner:np.ndarray, readout:np.ndarray, differentiate:int, scrambler:dict) -> list:\n",
    "    N=well_assigner.shape[0]\n",
    "    for i in range(differentiate):\n",
    "        resulti=[]\n",
    "        diff=i+1\n",
    "        if diff ==1:\n",
    "            resulti.extend(list(range(well_assigner.shape[0])))\n",
    "            full_well_assigner=well_assigner.copy()\n",
    "        else:\n",
    "            this_sc=scrambler[diff]\n",
    "            full_well_assigner=np.concatenate((full_well_assigner,np.bool(np.sum(well_assigner[this_sc], axis=1))))\n",
    "    idxs=[i for i in range(full_well_assigner.shape[0]) if np.array_equal(full_well_assigner[i,:],readout)]\n",
    "    if len(idxs)==0:\n",
    "        print('No match')\n",
    "        return(-1)\n",
    "    \n",
    "    return [resulti[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics_precomp(WA,3,scrambler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_deterministic_comparison(**kwargs):\n",
    "    methods=['matrix', 'random', 'STD', 'Chinese trick']\n",
    "    # matrix assignment\n",
    "    \n",
    "\n",
    "    # multidimensional matrix\n",
    "    if 'n_dims' in kwargs.keys():\n",
    "        WA_mul=assign_wells_multidim(**kwargs)\n",
    "        ndmin=kwargs['n_dims']\n",
    "        multi=['multidim: '+str(ndmin)]\n",
    "        WA_list=[WA_mul]\n",
    "    elif 'all_dims' in kwargs.keys():\n",
    "        if kwargs['all_dims']:\n",
    "            WA_list=[]\n",
    "            multi=[]\n",
    "            for i in np.arange(2,int(np.ceil(np.log(kwargs['n_compounds'])/np.log(2)))):\n",
    "                if i>kwargs['max_dims']:\n",
    "                    continue\n",
    "                WA_mul=assign_wells_multidim(n_dims=i, **kwargs)\n",
    "                WA_list.append(WA_mul)\n",
    "                multi.append('multidim: '+str(i))\n",
    "\n",
    "        else:\n",
    "            ndmin= find_dims(**kwargs)\n",
    "            WA_mul=assign_wells_multidim(n_dims=ndmin, **kwargs)\n",
    "            multi=['multidim: '+str(ndmin)]\n",
    "            WA_list=[WA_mul]\n",
    "            \n",
    "\n",
    "\n",
    "    else:\n",
    "        ndmin= find_dims(**kwargs)\n",
    "        WA_mul=assign_wells_multidim(n_dims=ndmin, **kwargs)\n",
    "        multi=['multidim: '+str(ndmin)]\n",
    "        WA_list=[WA_mul]\n",
    "    \n",
    "    multi.extend(methods)\n",
    "    methods=multi.copy()\n",
    "\n",
    "    WA_mat=assign_wells_mat(**kwargs)\n",
    "\n",
    "    # random assignment\n",
    "\n",
    "    WA_ran=assign_wells_random(**kwargs)\n",
    "\n",
    "    # STD asignment \n",
    "    WA_std=assign_wells_STD(**kwargs)\n",
    "\n",
    "    \n",
    "\n",
    "    # chinese trick assignment\n",
    "    WA_chin=assign_wells_chinese(**kwargs)\n",
    "\n",
    "\n",
    "    WA_list.extend([WA_mat, WA_ran,WA_std, WA_chin])\n",
    "\n",
    "    if kwargs['differentiate']<2:\n",
    "        WA_bin=assign_wells_L(**kwargs)\n",
    "        methods.append('Binary')\n",
    "        WA_list.append(WA_bin)\n",
    "\n",
    "    #hierarchical\n",
    "        \n",
    "    Hier=calculate_metrics_hierarchical(**kwargs)\n",
    "    #return([BM[0], BM[1],layers, MC, details ])\n",
    "\n",
    "    ls_met=[]\n",
    "    ls_names_met=['mean_experiments', 'max_compounds_per_well', 'n_wells', 'percentage_check', 'mean_extra_exp', 'mean_steps']\n",
    "    for method, WA in zip(methods, WA_list):\n",
    "        mean_exp, extra_exp,  _, perc_check= mean_metrics(WA, **kwargs)\n",
    "        n_wells=WA.shape[1]\n",
    "        M_exp=np.round(mean_exp, 2)\n",
    "        max_comp=np.max(np.sum(WA, axis=0))\n",
    "        ls_met.append([M_exp, max_comp, n_wells, int(perc_check),  extra_exp,1+perc_check/100])\n",
    "    ls_met.append(Hier[:-1])\n",
    "    full_methods=methods.copy()\n",
    "    full_methods.append('Hierarchical')\n",
    "    df_met=pd.DataFrame(ls_met)\n",
    "\n",
    "    dict_wa={method: WA for method, WA in zip(methods, WA_list)}\n",
    "    dict_wa.update({'Hierarchical':Hier[5]})\n",
    "\n",
    "    idx_renamer={i:j for i,j in zip(df_met.index, full_methods)}\n",
    "    col_renamer={i:j for i,j in zip(df_met.columns, ls_names_met)}\n",
    "    df_met.rename(index=idx_renamer, columns=col_renamer, inplace=True)\n",
    "\n",
    "    ret_wa= kwargs['return_wa'] \n",
    "    if ret_wa:\n",
    "        return df_met, dict_wa\n",
    "    return df_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./combinations/N_294.pk', 'rb') as handle:\n",
    "    f1=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2=iterative_add_N(f1,400, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1=add_N(F_dict,6,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cmb_dict.pk', 'wb') as handle:\n",
    "    pickle.dump(F1, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1[1000][4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(itertools.combinations(np.arange(1000),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri=add_1(dct_cmbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(itertools.combinations(np.arange(6),2))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_dir='./diff_1/20-47_step5.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_dir='./single_method/multidim_3/multidim_3__20-47_step5.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pk_dir, 'rb') as handle:\n",
    "    f1=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1[45]['WA'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To merge .pk files\n",
    "\n",
    "ls_names_met=['mean_experiments', 'max_compounds_per_well', 'n_wells', 'percentage_check', 'mean_extra_exp']\n",
    "full_dict={}\n",
    "for j in range(1,5):\n",
    "    base_dir='diff_'+str(j)\n",
    "    diff_dict={}\n",
    "    filenames = next(os.walk(base_dir), (None, None, []))[2]\n",
    "    for file in filenames:\n",
    "        full_dir=os.path.join(base_dir,file)\n",
    "        with open(full_dir, 'rb') as handle:\n",
    "            f1=pickle.load(handle)\n",
    "        for i in list(f1):\n",
    "            if i=='kwargs':\n",
    "                del f1['kwargs']\n",
    "                continue\n",
    "            else:\n",
    "                WA=assign_wells_mat(i)\n",
    "                f1[i][1].update({'matrix':WA})\n",
    "                mean_exp, extra_exp,  _, perc_check= mean_metrics(WA, differentiate=j)\n",
    "                n_wells=WA.shape[1]\n",
    "                M_exp=np.round(mean_exp, 2)\n",
    "                max_comp=np.max(np.sum(WA, axis=0))\n",
    "                ls_met=[M_exp, max_comp, n_wells, perc_check,  extra_exp]\n",
    "                f2=f1[i][0].drop(labels='matrix')\n",
    "                idxs=list(f2.index)\n",
    "                idxs+=['matrix']\n",
    "                r_idxs=idxs[-1:]+idxs[:-1]\n",
    "                dict_met={nm:list(f2[nm])+[val] for nm,val in zip(ls_names_met, ls_met)}\n",
    "\n",
    "                f1[i][0]=pd.DataFrame(data=dict_met, index=idxs).reindex(r_idxs)\n",
    "\n",
    "                \n",
    "                f1[i][0]=f1[i][0].round({'mean_extra_exp':2})\n",
    "            \n",
    "        diff_dict.update(f1)\n",
    "    full_str='Differentiate '+str(j)\n",
    "    full_dict.update({full_str:diff_dict})\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output as pickle file\n",
    "full_dir='Final_precomputed_file.pk'\n",
    "\n",
    "#with open(full_dir, 'wb') as handle:\n",
    "    #pickle.dump(full_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To merge files generated with inline_print\n",
    "all_methods = ['matrix', 'multidim', 'random', 'STD', 'CT', 'Binary']\n",
    "results = {}\n",
    "\n",
    "for method_dir in all_methods:\n",
    "    filenames = next(os.walk(method_dir), (None, None, []))[2]\n",
    "    metrics_list = []\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".txt\"):\n",
    "            try:\n",
    "                metrics = extract_metrics(file)\n",
    "                metrics[\"method\"] = method_dir\n",
    "                metrics_list.append(metrics)\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "    \n",
    "    if metrics_list:\n",
    "        df = pd.DataFrame(metrics_list)\n",
    "        df = df.sort_values(by=\"NS\")\n",
    "        \n",
    "        # Group by diff value\n",
    "        for diff_value, group_df in df.groupby(\"diff\"):\n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            \n",
    "            if diff_value not in results:\n",
    "                results['Differentiate ' + str(diff_value)] = {}\n",
    "                \n",
    "            for ns_value, ns_group_df in group_df.groupby(\"NS\"):\n",
    "                ns_group_df = ns_group_df.drop(columns=[\"diff\", \"NS\"]) \n",
    "                ns_group_df = ns_group_df.rename(columns={\"NW\": \"n_wells\", \"MS\": \"max_compounds_per_well\"})\n",
    "               \n",
    "                ns_group_df = ns_group_df.set_index([\"method\"])\n",
    "                \n",
    "                if ns_value not in results['Differentiate ' + str(diff_value)]:\n",
    "                    results['Differentiate ' + str(diff_value)][ns_value] = [ns_group_df, {}]\n",
    "                else:\n",
    "                    existing_df, empty_dict = results['Differentiate ' + str(diff_value)][ns_value]\n",
    "                    \n",
    "                    merged_df = pd.merge(existing_df.reset_index(), ns_group_df.reset_index(),\n",
    "                                         on=[\"method\", \"n_wells\", \"max_compounds_per_well\"], how=\"outer\", indicator=True)\n",
    "                    \n",
    "                    # Filter out rows that are duplicates (the '_merge' column indicates if it's from both dataframes)\n",
    "                    new_entries_df = merged_df[merged_df['_merge'] == 'right_only'].drop(columns=[\"_merge\"]).set_index(\"method\")\n",
    "                    existing_entries_df = merged_df[merged_df['_merge'] == 'both'].drop(columns=[\"_merge\"]).set_index(\"method\")\n",
    "                    \n",
    "                    # Concatenate only new entries\n",
    "                    combined_df = pd.concat([existing_entries_df, new_entries_df]).drop_duplicates().reset_index(drop=True)\n",
    "                    \n",
    "                    # Reassign the combined dataframe\n",
    "                    results['Differentiate ' + str(diff_value)][ns_value] = [combined_df, {}]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output as pickle file\n",
    "full_dir = 'Final_inline_precomputed_file.pk'\n",
    "\n",
    "# First check if file already exists\n",
    "# Merge new and old if it does\n",
    "if os.path.exists(full_dir):\n",
    "    with open(full_dir, \"rb\") as f:\n",
    "        existing_results = pickle.load(f)\n",
    "        \n",
    "    for diff_value, ns_values in results.items():\n",
    "        if diff_value not in existing_results:\n",
    "            existing_df, existing_empty_dict = existing_results[diff_value][ns_value]\n",
    "            \n",
    "            for ns_value, (new_df, empty_dict) in ns_values.items():\n",
    "                if ns_value in existing_results[diff_value]:\n",
    "                    existing_df, existing_empty_dict = existing_results[diff_value][ns_value]\n",
    "                \n",
    "            \n",
    "                    merged_df = pd.merge(existing_df.reset_index(), new_df.reset_index(),\n",
    "                                         on=[\"method\", \"n_wells\", \"max_compounds_per_well\"], how=\"outer\", indicator=True)\n",
    "                    \n",
    "                    new_entries_df = merged_df[merged_df['_merge'] == 'right_only'].drop(columns=[\"_merge\"]).set_index(\"method\")\n",
    "                    existing_entries_df = merged_df[merged_df['_merge'] == 'both'].drop(columns=[\"_merge\"]).set_index(\"method\")\n",
    "                    \n",
    "                    combined_df = pd.concat([existing_entries_df, new_entries_df]).drop_duplicates().reset_index(drop=True)\n",
    "                    existing_results[diff_value][ns_value] = [combined_df.set_index([\"method\"]), {}]\n",
    "                else:\n",
    "                    existing_results[diff_value][ns_value] = [new_df, empty_dict]\n",
    "            \n",
    "                \n",
    "    merged_results = existing_results\n",
    "    \n",
    "else:\n",
    "    merged_results = results\n",
    "\n",
    "#with open(full_dir, 'wb') as handle:\n",
    "    #pickle.dump(merged_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
