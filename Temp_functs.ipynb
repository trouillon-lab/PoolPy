{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=6\n",
    "dct_cmbn={}\n",
    "dct_cmbn.update({1:np.arange(N+1)})\n",
    "for j in range(2,5):\n",
    "    dct_cmbn.update({j:np.array(list(itertools.combinations(np.arange(N),j)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 1, 2, 3, 4, 5, 6]),\n",
       " 2: array([[0, 1],\n",
       "        [0, 2],\n",
       "        [0, 3],\n",
       "        [0, 4],\n",
       "        [0, 5],\n",
       "        [1, 2],\n",
       "        [1, 3],\n",
       "        [1, 4],\n",
       "        [1, 5],\n",
       "        [2, 3],\n",
       "        [2, 4],\n",
       "        [2, 5],\n",
       "        [3, 4],\n",
       "        [3, 5],\n",
       "        [4, 5]]),\n",
       " 3: array([[0, 1, 2],\n",
       "        [0, 1, 3],\n",
       "        [0, 1, 4],\n",
       "        [0, 1, 5],\n",
       "        [0, 2, 3],\n",
       "        [0, 2, 4],\n",
       "        [0, 2, 5],\n",
       "        [0, 3, 4],\n",
       "        [0, 3, 5],\n",
       "        [0, 4, 5],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 4],\n",
       "        [1, 2, 5],\n",
       "        [1, 3, 4],\n",
       "        [1, 3, 5],\n",
       "        [1, 4, 5],\n",
       "        [2, 3, 4],\n",
       "        [2, 3, 5],\n",
       "        [2, 4, 5],\n",
       "        [3, 4, 5]]),\n",
       " 4: array([[0, 1, 2, 3],\n",
       "        [0, 1, 2, 4],\n",
       "        [0, 1, 2, 5],\n",
       "        [0, 1, 3, 4],\n",
       "        [0, 1, 3, 5],\n",
       "        [0, 1, 4, 5],\n",
       "        [0, 2, 3, 4],\n",
       "        [0, 2, 3, 5],\n",
       "        [0, 2, 4, 5],\n",
       "        [0, 3, 4, 5],\n",
       "        [1, 2, 3, 4],\n",
       "        [1, 2, 3, 5],\n",
       "        [1, 2, 4, 5],\n",
       "        [1, 3, 4, 5],\n",
       "        [2, 3, 4, 5]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_cmbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_cmbn[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 7],\n",
       "       [1, 7],\n",
       "       [2, 7],\n",
       "       [3, 7],\n",
       "       [4, 7],\n",
       "       [5, 7],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([dct_cmbn[1],np.array([7]*7)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 7],\n",
       "       [0, 2, 7],\n",
       "       [0, 3, 7],\n",
       "       [0, 4, 7],\n",
       "       [0, 5, 7],\n",
       "       [1, 2, 7],\n",
       "       [1, 3, 7],\n",
       "       [1, 4, 7],\n",
       "       [1, 5, 7],\n",
       "       [2, 3, 7],\n",
       "       [2, 4, 7],\n",
       "       [2, 5, 7],\n",
       "       [3, 4, 7],\n",
       "       [3, 5, 7],\n",
       "       [4, 5, 7]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([dct_cmbn[2].T,np.array([7]*len(dct_cmbn[2]))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(itertools.combinations(np.arange(6),2))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_dir='./diff_1/20-47_step5.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_dir='./single_method/multidim_3/multidim_3__20-47_step5.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pk_dir, 'rb') as handle:\n",
    "    f1=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1[45]['WA'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To merge .pk files\n",
    "\n",
    "ls_names_met=['mean_experiments', 'max_compounds_per_well', 'n_wells', 'percentage_check', 'mean_extra_exp']\n",
    "full_dict={}\n",
    "for j in range(1,5):\n",
    "    base_dir='diff_'+str(j)\n",
    "    diff_dict={}\n",
    "    filenames = next(os.walk(base_dir), (None, None, []))[2]\n",
    "    for file in filenames:\n",
    "        full_dir=os.path.join(base_dir,file)\n",
    "        with open(full_dir, 'rb') as handle:\n",
    "            f1=pickle.load(handle)\n",
    "        for i in list(f1):\n",
    "            if i=='kwargs':\n",
    "                del f1['kwargs']\n",
    "                continue\n",
    "            else:\n",
    "                WA=assign_wells_mat(i)\n",
    "                f1[i][1].update({'matrix':WA})\n",
    "                mean_exp, extra_exp,  _, perc_check= mean_metrics(WA, differentiate=j)\n",
    "                n_wells=WA.shape[1]\n",
    "                M_exp=np.round(mean_exp, 2)\n",
    "                max_comp=np.max(np.sum(WA, axis=0))\n",
    "                ls_met=[M_exp, max_comp, n_wells, perc_check,  extra_exp]\n",
    "                f2=f1[i][0].drop(labels='matrix')\n",
    "                idxs=list(f2.index)\n",
    "                idxs+=['matrix']\n",
    "                r_idxs=idxs[-1:]+idxs[:-1]\n",
    "                dict_met={nm:list(f2[nm])+[val] for nm,val in zip(ls_names_met, ls_met)}\n",
    "\n",
    "                f1[i][0]=pd.DataFrame(data=dict_met, index=idxs).reindex(r_idxs)\n",
    "\n",
    "                \n",
    "                f1[i][0]=f1[i][0].round({'mean_extra_exp':2})\n",
    "            \n",
    "        diff_dict.update(f1)\n",
    "    full_str='Differentiate '+str(j)\n",
    "    full_dict.update({full_str:diff_dict})\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output as pickle file\n",
    "full_dir='Final_precomputed_file.pk'\n",
    "\n",
    "#with open(full_dir, 'wb') as handle:\n",
    "    #pickle.dump(full_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To merge files generated with inline_print\n",
    "all_methods = ['matrix', 'multidim', 'random', 'STD', 'CT', 'Binary']\n",
    "results = {}\n",
    "\n",
    "for method_dir in all_methods:\n",
    "    filenames = next(os.walk(method_dir), (None, None, []))[2]\n",
    "    metrics_list = []\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".txt\"):\n",
    "            try:\n",
    "                metrics = extract_metrics(file)\n",
    "                metrics[\"method\"] = method_dir\n",
    "                metrics_list.append(metrics)\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "    \n",
    "    if metrics_list:\n",
    "        df = pd.DataFrame(metrics_list)\n",
    "        df = df.sort_values(by=\"NS\")\n",
    "        \n",
    "        # Group by diff value\n",
    "        for diff_value, group_df in df.groupby(\"diff\"):\n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            \n",
    "            if diff_value not in results:\n",
    "                results['Differentiate ' + str(diff_value)] = {}\n",
    "                \n",
    "            for ns_value, ns_group_df in group_df.groupby(\"NS\"):\n",
    "                ns_group_df = ns_group_df.drop(columns=[\"diff\", \"NS\"]) \n",
    "                ns_group_df = ns_group_df.rename(columns={\"NW\": \"n_wells\", \"MS\": \"max_compounds_per_well\"})\n",
    "               \n",
    "                ns_group_df = ns_group_df.set_index([\"method\"])\n",
    "                \n",
    "                if ns_value not in results['Differentiate ' + str(diff_value)]:\n",
    "                    results['Differentiate ' + str(diff_value)][ns_value] = [ns_group_df, {}]\n",
    "                else:\n",
    "                    existing_df, empty_dict = results['Differentiate ' + str(diff_value)][ns_value]\n",
    "                    \n",
    "                    merged_df = pd.merge(existing_df.reset_index(), ns_group_df.reset_index(),\n",
    "                                         on=[\"method\", \"n_wells\", \"max_compounds_per_well\"], how=\"outer\", indicator=True)\n",
    "                    \n",
    "                    # Filter out rows that are duplicates (the '_merge' column indicates if it's from both dataframes)\n",
    "                    new_entries_df = merged_df[merged_df['_merge'] == 'right_only'].drop(columns=[\"_merge\"]).set_index(\"method\")\n",
    "                    existing_entries_df = merged_df[merged_df['_merge'] == 'both'].drop(columns=[\"_merge\"]).set_index(\"method\")\n",
    "                    \n",
    "                    # Concatenate only new entries\n",
    "                    combined_df = pd.concat([existing_entries_df, new_entries_df]).drop_duplicates().reset_index(drop=True)\n",
    "                    \n",
    "                    # Reassign the combined dataframe\n",
    "                    results['Differentiate ' + str(diff_value)][ns_value] = [combined_df, {}]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output as pickle file\n",
    "full_dir = 'Final_inline_precomputed_file.pk'\n",
    "\n",
    "# First check if file already exists\n",
    "# Merge new and old if it does\n",
    "if os.path.exists(full_dir):\n",
    "    with open(full_dir, \"rb\") as f:\n",
    "        existing_results = pickle.load(f)\n",
    "        \n",
    "    for diff_value, ns_values in results.items():\n",
    "        if diff_value not in existing_results:\n",
    "            existing_df, existing_empty_dict = existing_results[diff_value][ns_value]\n",
    "            \n",
    "            for ns_value, (new_df, empty_dict) in ns_values.items():\n",
    "                if ns_value in existing_results[diff_value]:\n",
    "                    existing_df, existing_empty_dict = existing_results[diff_value][ns_value]\n",
    "                \n",
    "            \n",
    "                    merged_df = pd.merge(existing_df.reset_index(), new_df.reset_index(),\n",
    "                                         on=[\"method\", \"n_wells\", \"max_compounds_per_well\"], how=\"outer\", indicator=True)\n",
    "                    \n",
    "                    new_entries_df = merged_df[merged_df['_merge'] == 'right_only'].drop(columns=[\"_merge\"]).set_index(\"method\")\n",
    "                    existing_entries_df = merged_df[merged_df['_merge'] == 'both'].drop(columns=[\"_merge\"]).set_index(\"method\")\n",
    "                    \n",
    "                    combined_df = pd.concat([existing_entries_df, new_entries_df]).drop_duplicates().reset_index(drop=True)\n",
    "                    existing_results[diff_value][ns_value] = [combined_df.set_index([\"method\"]), {}]\n",
    "                else:\n",
    "                    existing_results[diff_value][ns_value] = [new_df, empty_dict]\n",
    "            \n",
    "                \n",
    "    merged_results = existing_results\n",
    "    \n",
    "else:\n",
    "    merged_results = results\n",
    "\n",
    "#with open(full_dir, 'wb') as handle:\n",
    "    #pickle.dump(merged_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pooling_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
